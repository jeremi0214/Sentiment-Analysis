---
title: "R Project â€“ Sentiment Analysis"
author: "Jeremy Chen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Developing our Sentiment Analysis Model in R
First, we will load the dataset which is pre-loaded in R package 'janeaustenr'. For pre-processing the text data, we need to remove the noise by converting text to all lower cases and eliminating all punctuations and eradicating stop words. 

```{r}
library(tidytext)
sentiments
```

We will use the bing lexicon model, which classifies the sentiment into a binary category of negative or positive, to score the words respectively.
```{r}
get_sentiments("bing")
```

This step is to use janeaustenr package to get the textual data in the form of books, and use tidytext to perform efficient text analysis on the data. Then we will convert the text of books into a tidy format using unnest_tokens() function from stringr package.
```{r}
library(janeaustenr)
library(stringr)
library(tidytext)
library(dplyr)

tidy_data <- austen_books()  %>% 
  group_by(book) %>% 
  mutate(linenumber = row_number(),
         chapter = cumsum(
           str_detect(text, 
                      regex("^chapter [\\divxlc]",
                            ignore_case = TRUE)))) %>%
  ungroup() %>% 
  unnest_tokens(word, text)
```

Now, each row contains a single word, and we will make use of the "bing" lexicon to and implement filter() over the words that correspond to joy. We will implement out sentiment analysis model using the book Sense and Sensibility to derive its words.
```{r}
positive_senti <- get_sentiments("bing") %>% 
  filter(sentiment == "positive")

tidy_data %>% 
  filter(book == "Emma") %>% 
  semi_join(positive_senti) %>% 
  count(word, sort = TRUE)
```

Next step, we will use spread() function to segregate the data into separate coumns of positive and negative sentiments. Then using the mutate() function to calculate the total sentiment. 
```{r}
library(tidyr)

bing <- get_sentiments("bing")
Emma_sentiment <- tidy_data %>% 
  inner_join(bing) %>% 
  count(book = "Emma", index = linenumber %/% 80, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

In this step, we will visualise the words present in the book "Emma" based on their corosponding positive and negative scores.
```{r}
library(ggplot2)

ggplot(Emma_sentiment, aes(index, sentiment, fill = book)) +
  geom_bar(stat = "identity", show.legend = TRUE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

Then we will count the most common positive and negative words in the book.
```{r}
counting_words <- tidy_data %>% 
  inner_join(bing) %>% 
  count(word, sentiment, sort = TRUE)
head(counting_words)
```

Next step, we will visualise the sentiment score by plotting them along the axis with both positive and negative being labeled.
```{r}
counting_words %>% 
  filter(n > 150) %>% 
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(y = "Sentiment Score")
```

Last step, we will use comparision.cloud() function to create a wordcloud with both negative and positive words. 
```{r}
library(reshape2)
library(wordcloud)

tidy_data %>% 
  inner_join(bing) %>% 
  count(word, sentiment, sort = TRUE) %>% 
  acast(word ~ sentiment, value.var = "n", fill = 0) %>% 
  comparison.cloud(colors = c("red", "dark green"),
                   max.words = 100)
```

## Summary
In this sentiment analysis project, we went through Jane Austen's books and performed data wrangling for sentiment analysis. We used lexical analyser "bing" in this project and create various visualisations. 